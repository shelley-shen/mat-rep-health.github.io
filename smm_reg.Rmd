---
title: "Maternal Morbidity Regression"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
library(readr)
library(ggpubr)
library(corrplot)
library(RColorBrewer)
library(Hmisc)
library(patchwork)
library(rstatix)
library(glmnet)
library(MASS)

knitr::opts_chunk$set(
	fig.width = 9, 
  fig.asp = .6,
  out.width = "90%",
	warning = FALSE,
	message = FALSE
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

#### Linear Regression Model

Let's start by fitting a linear model to the severe maternal morbidity outcome using our stepwise AIC automatic feature selection algorithm. Next, we'll take a look at the chosen predictors, effect measures, and run regression diagnostics. 
```{r}
#Combined predictors with SMM outcome
predictor_df = read.csv("./data/predictors.csv")
outcome_df = read.csv("./data/outcomes.csv")
smm_df = predictor_df %>% 
  mutate(smm = outcome_df$smm)

#Fit the full model 
full_smm_linear.model <- lm(smm~., data = smm_df)
#Stepwise regression model
step_smm_linear.model <- stepAIC(full_smm_linear.model, direction = "both", 
                      trace = FALSE)

#Display converged model
step_smm_linear.model %>% 
  broom::tidy() %>%
  knitr::kable(digits = 3)
```

The variables female, hispanic, white, black, foreign_born, limited_eng, education, unemployment, late_no_prenatal_care, and clinics_and_chc_density were chosen in the final model. The model has an R-squared value of `r summary(step_smm_linear.model)$r.squared`, representing a reasonably good fit. 

However, we were concerned about our assumptions for linear regression, so they need to be 
checked before we can interpret any results. 

```{r}
#Regression diagnostics
plot(step_smm_linear.model)

#Shapiro test
smm_linear_shapiro = shapiro.test(residuals(step_smm_linear.model))
```
The Normal Q-Q plot has fat tails, suggesting violation of the normality assumption. This is confirmed with the Shapiro-Wilk test for normality, which has a p-value of `r smm_linear_shapiro$p.value`. The plot of residuals vs fitted values is non-random, suggesting a violation of the homoskedasticity assumption, also indicated by the scale-location plot, where the line is not straight. 

Let's try something else since it's clear the model doesn't follow linear assumptions.

#### Poisson Regression Model

Because our outcome variable, severe maternal morbidity rate is really a count variable (number of cases) made into a rate by dividing by total population (another variable in our dataset), we can fit Poisson regression to model the outcome. 

```{r}
full_smm_poisson.model <- glm(smm~., data=smm_df, family=poisson(link = "log"))

step_smm_poisson.model <- stepAIC(full_smm_poisson.model, direction = "both", 
                      trace = FALSE)

#Display converged model
step_smm_poisson.model %>% 
  broom::tidy() %>%
  knitr::kable(digits = 3)
```

Our Poisson model failed to converge, which is why it appears all 16 predictors were selected. 

#### Negative Binomial Regression Model

We will use a negative binomial model, an expansion on the Poisson model that adds a dispersion parameter alpha that can account for the overdispersion we found with the Poisson model

```{r}
full_smm_neg_bin.model <- glm.nb(smm~., data=smm_df)

step_smm_neg_bin.model <- stepAIC(full_smm_neg_bin.model, direction = "both", 
                      trace = FALSE)

#Display converged model
step_smm_neg_bin.model %>% 
  broom::tidy() %>%
  knitr::kable(digits = 3)
```

The negative binomial model selection process has yielded a more parsimonious set of predictors, including 8 predictors: hispanic, white, other, foreign_born, unemployment, medicaid_enroll, late_no_prenatal_care and clinics_and_chc_density.

This model is more parsimonious, and satisfies assumptions, which is not necessarily true for the linear and Poisson models. Let's compare the three models we've already built, and just for kicks, a negative binomial regression with variables selected through literature review & causal theory. 

```{r}
theory_smm_neg_bin.model <- glm.nb(smm~ late_no_prenatal_care + clinics_and_chc_density + medicaid_enroll + hispanic + black, data=smm_df)

#Display converged model
theory_smm_neg_bin.model %>% 
  broom::tidy() %>%
  knitr::kable(digits = 3)
```
Let's compare all four models using AIC and discuss the implications of these values.

  * Linear: AIC = `r AIC(step_smm_linear.model)`
  * Poisson: AIC = `r toString(step_smm_poisson.model$aic)`
  * Negative binomial: AIC = `r step_smm_neg_bin.model$aic`
  * Our model: AIC = `r theory_smm_neg_bin.model$aic`

Though the automatically generated negative binomial model has the lowest AIC and is therefore the "winning" model, it's important to note that our curated model is not far behind. Our curated model is also more parsimonious, contains fewer highly correlated predictors, and fits well with the existing body of literature on severe maternal morbidity, all of which are benefits difficult to quantify with a metric like AIC.

