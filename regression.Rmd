---
title: "regression"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
library(readr)
library(ggpubr)
library(corrplot)
library(RColorBrewer)
library(Hmisc)
library(patchwork)
library(rstatix)
library(glmnet)
library(MASS)

knitr::opts_chunk$set(
	fig.width = 9, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Preliminary regression diagnostics:

#### Normality of outcome variables
We have three outcome variables of interest: preterm births, severe maternal morbidity (SMM), and gonorrhea. 

We start by testing normality assumptions of dependent variables using histograms, Q-Q plots and Shapiro tests for normality.

```{r}
#separate outcomes into separate dataframe
outcome_df = project_df %>%
  dplyr::select(preterm_births, smm, gonorrhea)

#histograms
preterm_hist = ggplot(outcome_df, aes(x = preterm_births)) + geom_histogram()
smm_hist = ggplot(outcome_df, aes(x = smm)) + geom_histogram()
gonorrhea_hist = ggplot(outcome_df, aes(x = gonorrhea)) + geom_histogram()

#q-q plots
preterm_qq = ggqqplot(outcome_df$preterm_births)
smm_qq = ggqqplot(outcome_df$smm)
gonorrhea_qq = ggqqplot(project_df$gonorrhea)

#create patchwork plots
preterm_hist + preterm_qq

smm_hist + smm_qq

gonorrhea_hist + gonorrhea_qq

#run shapiro-wilk tests
outcome_df %>% shapiro_test(preterm_births, smm, gonorrhea) %>%
  knitr::kable(digits = 3)
```

Outcome variables are likely sampled from a non-normal distribution, as indicated by significant p-values for the Shapiro test and fat tails in the Q-Q plots: not a deal-breaker, since residuals are what are important, but certainly presents the possibility that linear regression may not be the best model for our data.

#### Exploratory linear regressions

(maybe should delete this part)

Let's start with some exploratory linear regressions with the outcome of several maternal morbidity:

```{r}
project_df = project_df %>%
  mutate(clinics_and_chc_density = ((clinics + community_health_centers)/total_pop)*10000,
         non_pcmd_density = (non_pcmd/total_pop)*10000) 
  

fit = lm(smm ~ clinics_and_chc_density, data = project_df)

fit %>% 
  broom::tidy() %>%
  knitr::kable()

project_df %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = clinics_and_chc_density, y = resid)) + geom_point()

summary(fit)$r.squared
```
These residuals are clearly skewed, with higher positive residuals and negative residuals. Linear regression is likely not appropriate here. Also this is a very bad fit, judging by the R-squared value.

Let's try adding poverty as a confounder:

Linear regression with health centers and poverty
```{r}
fit2 = lm(smm ~ clinics_and_chc_density + poverty, data = project_df)

fit2 %>% 
  broom::tidy() %>%
  knitr::kable()

project_df %>% 
  modelr::add_residuals(fit2) %>% 
  ggplot(aes(x = clinics_and_chc_density, y = resid)) + geom_point()

project_df %>% 
  modelr::add_residuals(fit2) %>% 
  ggplot(aes(x = poverty, y = resid)) + geom_point()

summary(fit2)$r.squared
```
The normality assumption remains violated, and the fit is better but still nowhere near where we'd like. It's possible things will improve with more predictors added to the model, but doing it by hand may take a while, so we're going to try automatic model selection and should maybe consider some other regression models.

### Analysis Plan

Moving forward, we will try two methods of regression: a multiple linear regression using our rate data, and a Poisson model using count data to account for a possible non-normal response distribution. 

Models will be selected with a stepwise automatic model selection process, which iteratively adds and removes predictors to the model until it converges. Please note that there is some debate regarding the statistical validity of stepwise model selection using AIC as a metric, further discussed in the appendix. For our purposes, we will use it for exploratory analysis due to ease of implementation and its intuitive approach and approach our results critically with respect to the algorithm's pitfalls.

Models will be judged on:
  * Satisfaction of assumptions for their respective method
  * Best fit as judged by Akaike information criterion (AIC), which considers both goodness-of-fit (rewarding models that explain higher variation in the outcome) and model parsimony (penalizing for too many predictors). AIC is applicable to both linear and Poisson models.

### Multicollinearity Considerations

Let's check for potential multicollinearity among predictors first, since stepwise model selection will exacerbate any existing multicollinearity in our model. 

The following steps were taken

* Remove identifiers like neighborhood names/NTA codes
* Remove outcome variables & pre-transformed variables (i.e. clinic count)
* Construct a Pearson correlation matrix of predictors, using pair-wise (instead of case) deletion of datapoints with missing values

```{r}
#create dataset of predictors ONLY
predictors_df = project_df %>% 
  dplyr::select(-c("nta_name","nta_code", "preterm_births", "gonorrhea", "smm", "clinics", "community_health_centers", "non_pcmd", "clinics_and_chc_count"))

N <- rcorr(as.matrix(predictors_df), type = c("pearson")) #pair-wise deletion
  
corrplot::corrplot(N$r,
                   type = "lower",
                   method = "square", 
                     addCoef.col = "black", 
                     diag = FALSE, 
                     number.cex = .6,
                     tl.col = "black",
                     tl.cex = .9,
                     tl.srt = 45)
```
There appears to several highly correlated potential predictors in our dataset, with strong positive and negative relationships present. There is a strong possibility of multicollinearity in our final models, so results will have to be viewed carefully. 

Most starkly, race remains highly correlated with health and SES-related outcomes at a neighborhood level. For example, there is a strong negative correlation between percent population that identifies as white and levels of poverty, unemployment, and late or no prenatal care. This relationship becomes positive when considering percent population that identifies as Hispanic. Surprisingly, proportion of population that identifies as black have weak to no relationship with SES-related outcomes like low educational attainment or poverty, but the strongest relationship with late or no prenatal care (R = 0.54)

### Outcome: Severe Maternal Morbidity 

#### Linear Regression Moel

Let's start by fitting a linear model to the severe maternal morbidity 
```{r}
#Combined predictors with SMM outcome
smm_linear_df = predictors_df %>% 
  mutate(smm = outcome_df$smm)

#Fit the full model 
full_smm_linear.model <- lm(smm~., data = smm_linear_df)
#Stepwise regression model
step_smm_linear.model <- stepAIC(full_smm_linear.model, direction = "both", 
                      trace = FALSE)
```

Next, we'll take a look at the chosen predictors, effect measures, and run regression diagnostics
```{r}
#Display converged model
step_smm_linear.model %>% 
  broom::tidy() %>%
  knitr::kable()
```
The variables female, hispanic, white_non_hisp, black_non_hisp, foreign_born, limited_eng, edu_less_than_hs, unemployment, late_no_prenatal_care, and clinics_and_chc_density were chosen in the final model. The model has an R-squared value of `summary(step_smm_linear.model)$r.squared`, representing a reasonably good fit. 

However, we were concerned about our assumptions for linear regression, so they need to be checked before we can interpret any results. 
```{r}
#Regression diagnostics
plot(step_smm_linear.model)

#Shapiro test
smm_linear_shapiro = shapiro.test(residuals(step_smm_linear.model))
```
The Normal Q-Q plot has fat tails, suggesting violation of the normality assumption. This is confirmed with the Shapiro-Wilk test for normality, which has a p-value of `smm_linear_shapiro$p.value`. The plot of residuals vs fitted values is non-random, suggesting a violation of the homoskedasticity assumption, also indicated by the scale-location plot, where the line is not straight. 

We'll stop this analysis here since it's clear the model doesn't follow linear assumptions.

## Building Poisson regression model

Since the underlying distribution is clearly non-linear, we will try a Poisson distribution. 

To do this, we will:

  * Convert the SMM variable, which is a rate per 10,000 back into a count using the number of live births
```{r}
Poisson_regression_df = project_df 
         
  
  
```

#### Outcome: Preterm Births

Let's start by fitting a linear model to the preterm births outcome
```{r}
#Combined predictors with preterm births outcome
preterm_linear_df = predictors_df %>% 
  mutate(preterm_births = outcome_df$preterm_births)

#Fit the full model 
full_preterm_linear.model <- lm(preterm_births~., data = preterm_linear_df)
#Stepwise regression model
step_preterm_linear.model <- stepAIC(full_preterm_linear.model, direction = "both", 
                      trace = FALSE)
```

Next, we'll take a look at the chosen predictors, effect measures, and run regression diagnostics
```{r}
#Display converged model
step_preterm_linear.model %>% 
  broom::tidy() %>%
  knitr::kable()

summary(step_preterm_linear.model)$r.squared
```
The 7 variables hispanic, black_non_hisp, other_race, limited_eng, health_ins, late_no_prenatal_care, and non_pcmd_density were chosen in the final model. The model has an R-squared value of `summary(step_preterm_linear.model)$r.squared`, representing a less-than-ideal fit with our predictor set

However, we were concerned about our assumptions for linear regression, so they need to be checked before we can interpret any results. 
```{r}
#Regression diagnostics
plot(step_preterm_linear.model)

#Shapiro test
preterm_linear_shapiro = shapiro.test(residuals(step_preterm_linear.model))
```
The linear regression assumptions are satisfied, so this is a valid model. The Normal Q-Q plot is reasonably well fit, and Shapiro-Wilk test for normality, which has a p-value of `preterm_linear_shapiro$p.value`, confirms the normality assumption. The data also roughly follows the homoskedasticity assumption, with 1 potential outlier outside 3 standard deviations or influential points. Though one point has high leverage, it is not higher than our rule-of-thumb threshold of 0.085. This is calculated using the rule of thumb equation 2(p + 1)/n, where p is the number of predictors and n the number of observations.

#### Outcome: Gonorrhea

Let's start by fitting a linear model to the gonorrhea outcome variable
```{r}
#Combined predictors with SMM outcome
gonorrhea_linear_df = predictors_df %>% 
  mutate(gonorrhea = outcome_df$gonorrhea)

#Fit the full model 
full_gonorrhea_linear.model <- lm(gonorrhea~., data = gonorrhea_linear_df)
#Stepwise regression model
step_gonorrhea_linear.model <- stepAIC(full_gonorrhea_linear.model, direction = "both", 
                      trace = FALSE)
```

Next, we'll take a look at the chosen predictors, effect measures, and run regression diagnostics
```{r}
#Display converged model
step_gonorrhea_linear.model %>% 
  broom::tidy() %>%
  knitr::kable()

summary(step_gonorrhea_linear.model)$r.squared
```
The variables female, hispanic, white_non_hisp, black_non_hisp, foreign_born, limited_eng, edu_less_than_hs, unemployment, late_no_prenatal_care, and clinics_and_chc_density were chosen in the final model. The model has an R-squared value of `summary(step_smm_linear.model)$r.squared`, representing a reasonably good fit. 

However, we were concerned about our assumptions for linear regression, so they need to be checked before we can interpret any results. 
```{r}
#Regression diagnostics
plot(step_gonorrhea_linear.model)

#Shapiro test
gonorrhea_linear_shapiro = shapiro.test(residuals(step_gonorrhea_linear.model))
```
The Normal Q-Q plot has fat tails, suggesting violation of the normality assumption. This is confirmed with the Shapiro-Wilk test for normality, which has a p-value of `gonorrhea_linear_shapiro$p.value`. The plot of residuals vs fitted values has non-random variance, suggesting a violation of the homoskedasticity assumption, also indicated by the scale-location plot, where the line is not straight. 

We'll stop this analysis here since it's clear the model doesn't follow linear assumptions, but it's important to note that further analysis would also have to investigate the potential outliers & high leverage points found in the residuals vs. leverage plot. 

A quick look at the dataset shows that both these data points, corresponding to the neighborhoods of Clinton (Hell's Kitchen) and Hudson Yards-Chelsea-Flat Iron-Union Square possess the highest and second highest rates of gonorrhea, respectively. These numbers are at odds with their majority white, affluent, and well-educated residents. We posit it may be because they have high LGBTQ+ populations - prior research [add link here?] suggests that MSM (men who have sex with men) are at much higher risk of STDs than women or heterosexual men. 


Poisson Regression
```{r}
offset_total_pop = log(predictors_df$total_pop)

gonorrhea_poisson_df = predictors_df %>%
  mutate(gonorrhea_count = round(project_df$gonorrhea*(total_pop/100000))) %>%
  dplyr::select(-total_pop)

full_gonorrhea_poisson.model <- glm(gonorrhea_count~.+offset(offset_total_pop), data=gonorrhea_poisson_df, family=poisson(link = "log"))

step_gonorrhea_poisson.model <- stepAIC(full_gonorrhea_poisson.model, direction = "both", 
                      trace = FALSE)

summary(step_gonorrhea_poisson.model)
```

```{r}
#Display converged model
step_gonorrhea_poisson.model %>% 
  broom::tidy() %>%
  knitr::kable()
```

Severe overdispersion (deviance/df >> 1): try negative binomial
```{r}

full_gonorrhea_neg_bin.model <- glm.nb(gonorrhea_count~.+offset(offset_total_pop), data=gonorrhea_poisson_df)

step_gonorrhea_neg_bin.model <- stepAIC(full_gonorrhea_neg_bin.model, direction = "both", 
                      trace = FALSE)

summary(step_gonorrhea_neg_bin.model)
```
This is much better! We will keep this model.

### Appendix


#### Stepwise model selection criticism
Naive, greedy algorithm prone to being stuck in local optima. 
link to Harrel (2001)
Future model selection using Lasso & LAR